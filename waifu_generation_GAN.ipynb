{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 1846858,
          "sourceType": "datasetVersion",
          "datasetId": 1098278
        }
      ],
      "dockerImageVersionId": 30559,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "        pass\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-12-21T12:40:25.388546Z",
          "iopub.execute_input": "2023-12-21T12:40:25.389166Z",
          "iopub.status.idle": "2023-12-21T12:41:00.956908Z",
          "shell.execute_reply.started": "2023-12-21T12:40:25.389133Z",
          "shell.execute_reply": "2023-12-21T12:41:00.956027Z"
        },
        "trusted": true,
        "id": "Mwh5KwgZewoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torch import nn, optim\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T12:41:00.958634Z",
          "iopub.execute_input": "2023-12-21T12:41:00.959308Z",
          "iopub.status.idle": "2023-12-21T12:41:00.965563Z",
          "shell.execute_reply.started": "2023-12-21T12:41:00.959274Z",
          "shell.execute_reply": "2023-12-21T12:41:00.964586Z"
        },
        "trusted": true,
        "id": "WY8WJztjewom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Check"
      ],
      "metadata": {
        "id": "GT_BR4Rqewon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device=torch.device('cuda')\n",
        "    print(device)\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "    print(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T12:41:00.966853Z",
          "iopub.execute_input": "2023-12-21T12:41:00.967264Z",
          "iopub.status.idle": "2023-12-21T12:41:00.979650Z",
          "shell.execute_reply.started": "2023-12-21T12:41:00.967205Z",
          "shell.execute_reply": "2023-12-21T12:41:00.978735Z"
        },
        "trusted": true,
        "id": "6CQYvRGFewoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "00vi3bAwewoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_list = glob.glob('/kaggle/input/gananime-lite/out2/*.png')\n",
        "print('total images:', len(image_list))\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "def display_random_images(image_paths, rows, cols):\n",
        "    # Calculate total number of images to display\n",
        "    total_images = rows * cols\n",
        "\n",
        "    # Shuffle the list of image file paths\n",
        "    random.shuffle(image_paths)\n",
        "\n",
        "    # Select total_images file paths from the shuffled list\n",
        "    selected_paths = image_paths[:total_images]\n",
        "\n",
        "    # Display these images in a grid format\n",
        "    for i, img_path in enumerate(selected_paths):\n",
        "        img = Image.open(img_path)\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def show_images(images, nmax=64):\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(make_grid(denorm(images.detach().cpu()[:nmax]), nrow=8).permute(1, 2, 0))\n",
        "\n",
        "display_random_images(image_list, 2, 2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T12:41:00.982012Z",
          "iopub.execute_input": "2023-12-21T12:41:00.982284Z",
          "iopub.status.idle": "2023-12-21T12:41:01.721986Z",
          "shell.execute_reply.started": "2023-12-21T12:41:00.982262Z",
          "shell.execute_reply": "2023-12-21T12:41:01.721056Z"
        },
        "trusted": true,
        "id": "p6WBh26Lewoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess and Load the data"
      ],
      "metadata": {
        "id": "alh0Zhlcewor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(image_list)\n",
        "df.to_csv('data.csv', index=False, header = None)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T12:41:01.723012Z",
          "iopub.execute_input": "2023-12-21T12:41:01.723298Z",
          "iopub.status.idle": "2023-12-21T12:41:01.825289Z",
          "shell.execute_reply.started": "2023-12-21T12:41:01.723274Z",
          "shell.execute_reply": "2023-12-21T12:41:01.824473Z"
        },
        "trusted": true,
        "id": "0WdFt3AQewor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T12:41:01.826494Z",
          "iopub.execute_input": "2023-12-21T12:41:01.826850Z",
          "iopub.status.idle": "2023-12-21T12:41:01.839906Z",
          "shell.execute_reply.started": "2023-12-21T12:41:01.826817Z",
          "shell.execute_reply": "2023-12-21T12:41:01.839065Z"
        },
        "trusted": true,
        "id": "OI1IReZSewos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The batch_size is defined by yourself based on the memory of GPU or CPU.\n",
        "batch_size = 128\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
        "transform = transforms.Compose([\n",
        "                                transforms.CenterCrop(500),\n",
        "                                transforms.Resize(64, interpolation=2),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(*stats)])\n",
        "def denorm(img_tensors):\n",
        "    return img_tensors * stats[1][0] + stats[0][0]\n",
        "\n",
        "class AnimeData(Dataset):\n",
        "    \"\"\"\n",
        "    Wrap the data into a Dataset class, and then pass it to the DataLoader\n",
        "    :__init__: Initialization data\n",
        "    :__getitem__: support the indexing such that dataset[i] can be used to get ith sample\n",
        "    :__len__: return the size of the dataset.\n",
        "    \"\"\"\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.frame = pd.read_csv(root, header=None)\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frame)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.frame.iloc[index, 0]\n",
        "        image = Image.open(image_name)\n",
        "        image = self.transform(image)\n",
        "        return image\n",
        "#TODO: Complete the trainloader\n",
        "trainset = AnimeData(root='./data.csv', transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size, shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T12:41:01.841373Z",
          "iopub.execute_input": "2023-12-21T12:41:01.841647Z",
          "iopub.status.idle": "2023-12-21T12:41:01.878536Z",
          "shell.execute_reply.started": "2023-12-21T12:41:01.841623Z",
          "shell.execute_reply": "2023-12-21T12:41:01.877779Z"
        },
        "trusted": true,
        "id": "JBSHdmbRewot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator"
      ],
      "metadata": {
        "id": "9sGeV6Hrewot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Create your Discriminator model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,inchannels):\n",
        "        super(Discriminator,self).__init__()\n",
        "        \"\"\"\n",
        "        Initialize the Discriminator Module\n",
        "        :param inchannels: The depth of the first convolutional layer\n",
        "        \"\"\"\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=2, padding=0),\n",
        "            nn.Flatten(),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        \"\"\"\n",
        "        Forward propagation of the neural network\n",
        "        :param x: The input to the neural network\n",
        "        :return: Discriminator logits; the output of the neural network\n",
        "        \"\"\"\n",
        "        x = self.conv_block1(x)\n",
        "        return x\n",
        "\n",
        "D=Discriminator(3).to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T12:41:01.879479Z",
          "iopub.execute_input": "2023-12-21T12:41:01.879734Z",
          "iopub.status.idle": "2023-12-21T12:41:01.939289Z",
          "shell.execute_reply.started": "2023-12-21T12:41:01.879705Z",
          "shell.execute_reply": "2023-12-21T12:41:01.938418Z"
        },
        "trusted": true,
        "id": "oFazuj9Eewot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator"
      ],
      "metadata": {
        "id": "o7Vqk7BHewou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your Generator model\n",
        "latent_size = 128\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self,latent_size):\n",
        "        super(Generator,self).__init__()\n",
        "        \"\"\"\n",
        "        Initialize the Generator Module\n",
        "        :param latent_size: The length of the input latent vector\n",
        "        \"\"\"\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=latent_size, out_channels=512, kernel_size=4, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        \"\"\"\n",
        "        Forward propagation of the neural network\n",
        "        :param x: The input to the neural network\n",
        "        :return: A 3x64x64 Tensor image as output\n",
        "        \"\"\"\n",
        "        x = self.conv_block1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "G=Generator(latent_size).to(device)\n",
        "# random latent tensors\n",
        "noise = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
        "\n",
        "fake_images = G(noise)\n",
        "print(fake_images.shape)\n",
        "\n",
        "for real_images in tqdm(trainloader):\n",
        "    real_images=(real_images).to(device)\n",
        "\n",
        "show_images(fake_images)\n",
        "show_images(real_images)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T12:41:01.940464Z",
          "iopub.execute_input": "2023-12-21T12:41:01.940782Z",
          "iopub.status.idle": "2023-12-21T12:50:58.449458Z",
          "shell.execute_reply.started": "2023-12-21T12:41:01.940758Z",
          "shell.execute_reply": "2023-12-21T12:50:58.448536Z"
        },
        "trusted": true,
        "id": "ahO9gcB5ewou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Losses and Optiomiziers"
      ],
      "metadata": {
        "id": "VC1J4x7gewou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "def Real_loss(preds,targets):\n",
        "    '''\n",
        "       Calculates how close discriminator outputs are to being real.\n",
        "       param, D_out: discriminator logits\n",
        "       return: real loss\n",
        "    '''\n",
        "    beta_distr = torch.distributions.beta.Beta(1,5,validate_args=None)\n",
        "    label_noise = beta_distr.sample(sample_shape=targets.shape).to(torch.device(device))\n",
        "    loss= loss_fn(targets,preds-label_noise)\n",
        "    return loss\n",
        "\n",
        "def Fake_loss(preds,targets):\n",
        "    '''\n",
        "       Calculates how close discriminator outputs are to being fake.\n",
        "       param, D_out: discriminator logits\n",
        "       return: fake loss\n",
        "    '''\n",
        "    beta_distr = torch.distributions.beta.Beta(1,5,validate_args=None)\n",
        "    label_noise = beta_distr.sample(sample_shape=targets.shape).to(torch.device(device))\n",
        "    loss= loss_fn(targets,preds+label_noise)\n",
        "    return loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T12:50:58.452676Z",
          "iopub.execute_input": "2023-12-21T12:50:58.453030Z",
          "iopub.status.idle": "2023-12-21T12:50:58.462085Z",
          "shell.execute_reply.started": "2023-12-21T12:50:58.453000Z",
          "shell.execute_reply": "2023-12-21T12:50:58.461153Z"
        },
        "trusted": true,
        "id": "b21dhcxBewov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create optimizers for the discriminator D and generator G\n",
        "#Define your learning rate\n",
        "lr=0.0002\n",
        "opt_d = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "opt_g = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T12:50:58.463279Z",
          "iopub.execute_input": "2023-12-21T12:50:58.463603Z",
          "iopub.status.idle": "2023-12-21T12:50:58.479597Z",
          "shell.execute_reply.started": "2023-12-21T12:50:58.463577Z",
          "shell.execute_reply": "2023-12-21T12:50:58.478843Z"
        },
        "trusted": true,
        "id": "Kd5-Pc1Bewov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Define your save path.\n",
        "sample_dir = 'generated'\n",
        "os.makedirs(sample_dir, exist_ok=True)\n",
        "def save_samples(index, latent_tensors, generator, show=True):\n",
        "    fake_images = generator(latent_tensors)\n",
        "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
        "    print('Saving', fake_fname)\n",
        "    if show:\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))\n",
        "        plt.show()\n",
        "fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T12:50:58.480764Z",
          "iopub.execute_input": "2023-12-21T12:50:58.481031Z",
          "iopub.status.idle": "2023-12-21T12:50:58.493579Z",
          "shell.execute_reply.started": "2023-12-21T12:50:58.481009Z",
          "shell.execute_reply": "2023-12-21T12:50:58.492783Z"
        },
        "trusted": true,
        "id": "d994iaVKewov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "g8XdqLQBewov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the training function\n",
        "losses_g = []\n",
        "losses_d = []\n",
        "real_scores = []\n",
        "fake_scores = []\n",
        "def train(D, G, d_optimizer, g_optimizer, epochs=1):\n",
        "    iter_count = 0\n",
        "    start_idx=1\n",
        "    for epoch in range(epochs):\n",
        "        for real_images in tqdm(trainloader):\n",
        "            real_images=real_images.to(device)\n",
        "            # Pass real images through discriminator\n",
        "            D_out_real = D(real_images)\n",
        "            label_real = torch.full(D_out_real.shape, 1.0).to(torch.device(device))\n",
        "            real_loss = Real_loss(label_real,D_out_real)\n",
        "            real_score = torch.mean(D_out_real).item()\n",
        "\n",
        "            # Generate fake images\n",
        "            noise = torch.randn(batch_size, latent_size, 1, 1).to(torch.device(device))\n",
        "            fake_images =  G(noise)\n",
        "\n",
        "            # Pass fake images through discriminator\n",
        "            D_out_fake = D(fake_images)\n",
        "            label_fake =  torch.full(D_out_fake.shape, 0).to(torch.device(device))\n",
        "            fake_loss = Fake_loss(label_fake, D_out_fake)\n",
        "            fake_score = torch.mean(D_out_fake).item()\n",
        "\n",
        "            # Update discriminator weights\n",
        "            loss_d = real_loss + fake_loss\n",
        "\n",
        "            d_optimizer.zero_grad()\n",
        "            loss_d.backward(retain_graph = True)\n",
        "            d_optimizer.step()\n",
        "\n",
        "            # Generate fake images\n",
        "            noise2 = torch.randn(batch_size, latent_size, 1, 1).to(torch.device(device))\n",
        "            fake_images2 =  G(noise2)\n",
        "\n",
        "            gen_steps = 1\n",
        "            for i in range(0, gen_steps ):\n",
        "            # Try to fool the discriminator\n",
        "                D_out_fake2 = D(fake_images2)\n",
        "\n",
        "                # The label is set to 1(real-like) to fool the discriminator\n",
        "                label_real1 = torch.full(D_out_fake2.shape, 1.0).to(torch.device(device))\n",
        "                loss_g = Real_loss(label_real1, D_out_fake2)\n",
        "\n",
        "                # Update generator weights\n",
        "                g_optimizer.zero_grad()\n",
        "                loss_g.backward(retain_graph = (i<gen_steps -1 ))\n",
        "                g_optimizer.step()\n",
        "\n",
        "\n",
        "        losses_g.append(loss_g.item())\n",
        "        losses_d.append(loss_d.item())\n",
        "        real_scores.append(real_score)\n",
        "        fake_scores.append(fake_score)\n",
        "        # Log losses & scores (last batch)\n",
        "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
        "        epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
        "\n",
        "        # Save generated images\n",
        "        save_samples(epoch+start_idx, fixed_latent,G, show=True)\n",
        "\n",
        "        state_dis = {'dis_model': D.state_dict(), 'epoch': epoch}\n",
        "        state_gen = {'gen_model': G.state_dict(), 'epoch': epoch}\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        if epoch == 99:\n",
        "            torch.save(state_dis, 'checkpoint/'+'D__'+str(epoch+1)) #each epoch\n",
        "            torch.save(state_gen, 'checkpoint/'+'G__'+str(epoch+1)) #each epoch\n",
        "#Train the GAN\n",
        "train(D,G,opt_d,opt_g,epochs=50)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T12:50:58.494934Z",
          "iopub.execute_input": "2023-12-21T12:50:58.495284Z",
          "iopub.status.idle": "2023-12-21T17:33:37.273989Z",
          "shell.execute_reply.started": "2023-12-21T12:50:58.495237Z",
          "shell.execute_reply": "2023-12-21T17:33:37.273105Z"
        },
        "trusted": true,
        "id": "k5f1Blocewov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "GiTdizusewow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Visualize your loss curve of D and G\n",
        "fig, ax = plt.subplots()\n",
        "plt.plot(losses_g, label='Discriminator', alpha=0.5)\n",
        "plt.plot(losses_d, label='Generator', alpha=0.5)\n",
        "plt.title(\"Training Losses\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T17:33:37.275194Z",
          "iopub.execute_input": "2023-12-21T17:33:37.275479Z",
          "iopub.status.idle": "2023-12-21T17:33:37.578160Z",
          "shell.execute_reply.started": "2023-12-21T17:33:37.275454Z",
          "shell.execute_reply": "2023-12-21T17:33:37.577228Z"
        },
        "trusted": true,
        "id": "neWZTFOXewow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /kaggle/working/generated.zip /kaggle/working/generated"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-21T17:34:57.819922Z",
          "iopub.execute_input": "2023-12-21T17:34:57.820288Z",
          "iopub.status.idle": "2023-12-21T17:34:59.737563Z",
          "shell.execute_reply.started": "2023-12-21T17:34:57.820260Z",
          "shell.execute_reply": "2023-12-21T17:34:59.736576Z"
        },
        "trusted": true,
        "id": "PNoMW9vqewow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MEofJVYAewox"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}